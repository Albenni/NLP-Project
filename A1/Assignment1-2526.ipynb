{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE4WC2_4wygJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 1\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Sexism Detection, Multi-class Classification, RNNs, Transformers, Huggingface\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL69zGpmx01k",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contact\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "- Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "- Eleonora Mancini -> e.mancini@unibo.it\n",
    "\n",
    "Professor:\n",
    "- Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55jnW-xKxi-2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "You are asked to address the [EXIST 2023 Task 2](https://clef2023.clef-initiative.eu/index.php?page=Pages/labs.html#EXIST) on sexism detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HWp5bGwySsb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem Definition\n",
    "\n",
    "This task aims to categorize the sexist messages according to the intention of the author in one of the following categories: (i) direct sexist message, (ii) reported sexist message and (iii) judgemental message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples:\n",
    "\n",
    "#### DIRECT \n",
    "The intention was to write a message that is sexist by itself or incites to be sexist, as in:\n",
    "\n",
    "''*A woman needs love, to fill the fridge, if a man can give this to her in return for her services (housework, cooking, etc), I don’t see what else she needs.*''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### REPORTED\n",
    "The intention is to report and share a sexist situation suffered by a woman or women in first or third person, as in:\n",
    "\n",
    "''*Today, one of my year 1 class pupils could not believe he’d lost a race against a girl.*''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### JUDGEMENTAL\n",
    "The intention was to judge, since the tweet describes sexist situations or behaviours with the aim of condemning them.\n",
    "\n",
    "''*As usual, the woman was the one quitting her job for the family’s welfare…*''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iu1X4I98M8B",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 1 - 1.0 points] Corpus\n",
    "\n",
    "We have preparared a small version of EXIST dataset in our dedicated [Github repository](https://github.com/lt-nlp-lab-unibo/nlp-course-material/tree/main/2025-2026/Assignment%201/data).\n",
    "\n",
    "Check the `A1/data` folder. It contains 3 `.json` files representing `training`, `validation` and `test` sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AASoMV9XN5l6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset Description\n",
    "- The dataset contains tweets in both English and Spanish.\n",
    "- There are labels for multiple tasks, but we are focusing on **Task 2**.\n",
    "- For Task 2, labels are assigned by six annotators.\n",
    "- The labels for Task 2 represent whether the tweet is non-sexist ('-') or its sexist intention ('DIRECT', 'REPORTED', 'JUDGEMENTAL').\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFjwB_lCOQKj",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Example\n",
    "\n",
    "```\n",
    "    \"203260\": {\n",
    "        \"id_EXIST\": \"203260\",\n",
    "        \"lang\": \"en\",\n",
    "        \"tweet\": \"ik when mandy says “you look like a whore” i look cute as FUCK\",\n",
    "        \"number_annotators\": 6,\n",
    "        \"annotators\": [\"Annotator_473\", \"Annotator_474\", \"Annotator_475\", \"Annotator_476\", \"Annotator_477\", \"Annotator_27\"],\n",
    "        \"gender_annotators\": [\"F\", \"F\", \"M\", \"M\", \"M\", \"F\"],\n",
    "        \"age_annotators\": [\"18-22\", \"23-45\", \"18-22\", \"23-45\", \"46+\", \"46+\"],\n",
    "        \"labels_task1\": [\"YES\", \"YES\", \"YES\", \"NO\", \"YES\", \"YES\"],\n",
    "        \"labels_task2\": [\"DIRECT\", \"DIRECT\", \"REPORTED\", \"-\", \"JUDGEMENTAL\", \"REPORTED\"],\n",
    "        \"labels_task3\": [\n",
    "          [\"STEREOTYPING-DOMINANCE\"],\n",
    "          [\"OBJECTIFICATION\"],\n",
    "          [\"SEXUAL-VIOLENCE\"],\n",
    "          [\"-\"],\n",
    "          [\"STEREOTYPING-DOMINANCE\", \"OBJECTIFICATION\"],\n",
    "          [\"OBJECTIFICATION\"]\n",
    "        ],\n",
    "        \"split\": \"TRAIN_EN\"\n",
    "      }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ45bvuOOJ7I",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "1. **Download** the `A1/data` folder.\n",
    "2. **Load** the three JSON files and encode them as ``pandas.DataFrame``.\n",
    "3. **Aggregate labels** for Task 2 using majority voting and store them in a new dataframe column called `label`. Items without a clear majority will be removed from the dataset.\n",
    "4. **Filter the DataFrame** to keep only rows where the `lang` column is `'en'`.\n",
    "5. **Remove unwanted columns**: Keep only `id_EXIST`, `lang`, `tweet`, and `label`.\n",
    "6. **Encode the `label` column**: Use the following mapping\n",
    "\n",
    "```\n",
    "{\n",
    "    '-': 0,\n",
    "    'DIRECT': 1,\n",
    "    'JUDGEMENTAL': 2,\n",
    "    'REPORTED': 3\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN]\n",
      "- Dropped (no majority): 2375\n",
      "- Dropped (non-EN): 2333\n",
      "Label distribution (encoded):\n",
      "label\n",
      "0    1735\n",
      "1     340\n",
      "2      43\n",
      "3      94\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "[VALIDATION]\n",
      "- Dropped (no majority): 259\n",
      "- Dropped (non-EN): 352\n",
      "Label distribution (encoded):\n",
      "label\n",
      "0    90\n",
      "1    14\n",
      "2     7\n",
      "3     4\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "[TEST]\n",
      "- Dropped (no majority): 95\n",
      "- Dropped (non-EN): 0\n",
      "Label distribution (encoded):\n",
      "label\n",
      "0    160\n",
      "1     42\n",
      "2      5\n",
      "3     10\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Saved to: C:\\CODING\\NLP-Project\\A1\\processed\n"
     ]
    }
   ],
   "source": [
    "# === TASK 1 (lean) — EXIST / Task 2 ===\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "FILES = {\n",
    "    \"train\":      DATA_DIR / \"training.json\",\n",
    "    \"validation\": DATA_DIR / \"validation.json\",\n",
    "    \"test\":       DATA_DIR / \"test.json\",\n",
    "}\n",
    "\n",
    "# Label mapping required by the assignment\n",
    "LABEL_MAP = {\"-\": 0, \"DIRECT\": 1, \"JUDGEMENTAL\": 2, \"REPORTED\": 3}\n",
    "ALLOWED_LABELS = set(LABEL_MAP.keys())  # ignore anything else (e.g., UNKNOWN)\n",
    "\n",
    "def read_json_df(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load EXIST split stored as dict-of-dicts and convert to DataFrame.\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data, orient=\"index\").reset_index(drop=True)\n",
    "    if \"id_EXIST\" not in df.columns:\n",
    "        print(\"primo if\")\n",
    "        # if the payload doesn't carry id, use the original keys\n",
    "        df[\"id_EXIST\"] = list(data.keys())\n",
    "    return df\n",
    "\n",
    "\n",
    "def majority_vote(labels):\n",
    "    \"\"\"\n",
    "    Strict majority on Task 2 labels:\n",
    "    - keep only labels in ALLOWED_LABELS\n",
    "    - return None if no clear winner (> 50%)\n",
    "    \"\"\"\n",
    "    labels_norm = [str(x).strip().upper() for x in labels if isinstance(x, str)]\n",
    "    labels_norm = [x for x in labels_norm if x in ALLOWED_LABELS]\n",
    "    lab, cnt = Counter(labels_norm).most_common(1)[0]\n",
    "    return lab if cnt > len(labels_norm) / 2 else None\n",
    "\n",
    "def process_split(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1) majority vote on Task 2\n",
    "    df[\"label_str\"] = df[\"labels_task2\"].apply(majority_vote)\n",
    "\n",
    "    # 2) drop rows without clear majority\n",
    "    before = len(df)\n",
    "    df = df[df[\"label_str\"].notna()].copy()\n",
    "    dropped_majority = before - len(df)\n",
    "\n",
    "    # 3) keep English only (accept 'en' and 'en-*')\n",
    "    before = len(df)\n",
    "    df = df[df[\"lang\"].astype(str).str.lower() == \"en\"].copy()\n",
    "    dropped_lang = before - len(df)\n",
    "\n",
    "    # 4) keep and encode required columns\n",
    "    df = df[[\"id_EXIST\", \"lang\", \"tweet\", \"label_str\"]].rename(columns={\"label_str\": \"label\"})\n",
    "    df[\"label\"] = df[\"label\"].map(LABEL_MAP).astype(\"Int64\")\n",
    "\n",
    "    # quick report\n",
    "    print(f\"- Dropped (no majority): {dropped_majority}\")\n",
    "    print(f\"- Dropped (non-EN): {dropped_lang}\")\n",
    "    print(\"Label distribution (encoded):\")\n",
    "    print(df[\"label\"].value_counts().sort_index())\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---- Run and save ----\n",
    "df_train_raw = read_json_df(FILES[\"train\"])\n",
    "df_val_raw   = read_json_df(FILES[\"validation\"])\n",
    "df_test_raw  = read_json_df(FILES[\"test\"])\n",
    "\n",
    "print(\"\\n[TRAIN]\")\n",
    "df_train = process_split(df_train_raw)\n",
    "print(\"\\n[VALIDATION]\")\n",
    "df_val   = process_split(df_val_raw)\n",
    "print(\"\\n[TEST]\")\n",
    "df_test  = process_split(df_test_raw)\n",
    "\n",
    "out_dir = Path(\"processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "df_train.to_csv(out_dir / \"train.csv\", index=False)\n",
    "df_val.to_csv(out_dir / \"validation.csv\", index=False)\n",
    "df_test.to_csv(out_dir / \"test.csv\", index=False)\n",
    "print(f\"\\nSaved to: {out_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>200002</td>\n",
       "      <td>en</td>\n",
       "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>200006</td>\n",
       "      <td>en</td>\n",
       "      <td>According to a customer I have plenty of time ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>200008</td>\n",
       "      <td>en</td>\n",
       "      <td>New to the shelves this week - looking forward...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>200010</td>\n",
       "      <td>en</td>\n",
       "      <td>I guess that’s fairly normal for a Neanderthal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>200011</td>\n",
       "      <td>en</td>\n",
       "      <td>#EverydaySexism means women usually end up in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_EXIST lang                                              tweet  label\n",
       "3661   200002   en  Writing a uni essay in my local pub with a cof...      3\n",
       "3665   200006   en  According to a customer I have plenty of time ...      3\n",
       "3667   200008   en  New to the shelves this week - looking forward...      0\n",
       "3669   200010   en  I guess that’s fairly normal for a Neanderthal...      0\n",
       "3670   200011   en  #EverydaySexism means women usually end up in ...      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task2 - 0.5 points] Data Cleaning\n",
    "In the context of tweets, we have noisy and informal data that often includes unnecessary elements like emojis, hashtags, mentions, and URLs. These elements may interfere with the text analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Instructions\n",
    "- **Remove emojis** from the tweets.\n",
    "- **Remove hashtags** (e.g., `#example`).\n",
    "- **Remove mentions** such as `@user`.\n",
    "- **Remove URLs** from the tweets.\n",
    "- **Remove special characters and symbols**.\n",
    "- **Remove specific quote characters** (e.g., curly quotes).\n",
    "- **Perform lemmatization** to reduce words to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TRAIN] reading processed\\train.csv ...\n",
      "   id_EXIST lang                                              tweet  label\n",
      "0    200002   en  write a uni essay in my local pub with a coffe...      3\n",
      "1    200006   en  accord to a customer i have plenty of time to ...      3\n",
      " -> saved cleaned split to processed\\train.csv (2212 rows)\n",
      "\n",
      "[VALIDATION] reading processed\\validation.csv ...\n",
      "   id_EXIST lang                                              tweet  label\n",
      "0    400001   en  you should smile more love just pretend you re...      0\n",
      "1    400003   en  some man move my suitcase in the overhead lugg...      3\n",
      " -> saved cleaned split to processed\\validation.csv (115 rows)\n",
      "\n",
      "[TEST] reading processed\\test.csv ...\n",
      "   id_EXIST lang                                              tweet  label\n",
      "0    400178   en  1st day at the pool on a beautiful sunday in n...      0\n",
      "1    400180   en  same though the angst just come and go lonely ...      0\n",
      " -> saved cleaned split to processed\\test.csv (217 rows)\n"
     ]
    }
   ],
   "source": [
    "# === TASK 2 — CLEANING & LEMMATIZATION ===\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "for resource in [\"punkt\", \"punkt_tab\", \"wordnet\", \"omw-1.4\"]:\n",
    "    try:\n",
    "        if resource == \"punkt_tab\":\n",
    "            nltk.data.find(f\"tokenizers/{resource}\")\n",
    "        else:\n",
    "            nltk.data.find(resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource, quiet=True)\n",
    "\n",
    "pos_tagger_found = False\n",
    "for pos_resource in [\"averaged_perceptron_tagger_eng\", \"averaged_perceptron_tagger\"]:\n",
    "    if not pos_tagger_found:\n",
    "        try:\n",
    "            nltk.data.find(f\"taggers/{pos_resource}\")\n",
    "            pos_tagger_found = True\n",
    "        except LookupError:\n",
    "            try:\n",
    "                nltk.download(pos_resource, quiet=True)\n",
    "                pos_tagger_found = True\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Regex patterns for text cleaning\n",
    "# ------------------------------------------------------------------\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\", flags=re.IGNORECASE)\n",
    "MENTION_RE = re.compile(r\"@\\w+\")\n",
    "HASHTAG_RE = re.compile(r\"#\\w+\")\n",
    "EMOJI_RE = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    \"\\U00002700-\\U000027BF\"  # dingbats\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # supplemental symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # extended pictographs\n",
    "    \"\\U00002600-\\U000026FF\"  # misc symbols\n",
    "    \"]+\",\n",
    "    flags=re.UNICODE,\n",
    ")\n",
    "FANCY_QUOTES_RE = re.compile(r\"[“”‘’´`]\")\n",
    "SPECIAL_CHARS_RE = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    \"\"\"Collapse multiple spaces/newlines to a single space and trim.\"\"\"\n",
    "    return WHITESPACE_RE.sub(\" \", text).strip()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions for POS tagging\n",
    "# ------------------------------------------------------------------\n",
    "def penn_to_wordnet_pos(tag: str):\n",
    "    \"\"\"\n",
    "    Convert Penn Treebank POS tags\n",
    "    into the POS format expected by WordNetLemmatizer.\n",
    "    If the tag is unknown, default to noun.\n",
    "    \"\"\"\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatize_tokens_pos(tokens):\n",
    "    \"\"\"\n",
    "    Lemmatize each token using its predicted POS tag.\n",
    "    \"\"\"\n",
    "    # POS tagging on tokens\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "    lemmas = []\n",
    "    for word, pos_tag in tagged:\n",
    "        wn_pos = penn_to_wordnet_pos(pos_tag)\n",
    "        lemmas.append(lemmatizer.lemmatize(word, pos=wn_pos))\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Full cleaning pipeline for a single tweet\n",
    "# ------------------------------------------------------------------\n",
    "def clean_tweet(text: str) -> str:\n",
    "    t = text.lower()\n",
    "\n",
    "    # remove urls, mentions, hashtags, emojis\n",
    "    t = URL_RE.sub(\" \", t)\n",
    "    t = MENTION_RE.sub(\" \", t)\n",
    "    t = HASHTAG_RE.sub(\" \", t)\n",
    "    t = EMOJI_RE.sub(\" \", t)\n",
    "\n",
    "    # remove fancy quotes\n",
    "    t = FANCY_QUOTES_RE.sub(\" \", t)\n",
    "\n",
    "    # remove remaining non-alphanumeric chars / punctuation (keep only [a-z0-9 space])\n",
    "    t = SPECIAL_CHARS_RE.sub(\" \", t)\n",
    "\n",
    "    # normalize whitespace before tokenizing\n",
    "    t = normalize_whitespace(t)\n",
    "\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(t)\n",
    "\n",
    "    # POS-aware lemmatization\n",
    "    t = lemmatize_tokens_pos(tokens)\n",
    "\n",
    "    # final whitespace cleanup\n",
    "    t = normalize_whitespace(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Apply cleaning to entire DataFrame\n",
    "# ------------------------------------------------------------------\n",
    "def apply_cleaning(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"tweet\"] = df[\"tweet\"].astype(str).apply(clean_tweet)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load and clean CSVs (train / validation / test)\n",
    "# ------------------------------------------------------------------\n",
    "in_dir = out_dir = Path(\"processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "splits = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "for split in splits:\n",
    "    in_path = in_dir / f\"{split}.csv\"\n",
    "    print(f\"\\n[{split.upper()}] reading {in_path} ...\")\n",
    "    df_split = pd.read_csv(in_path)\n",
    "\n",
    "    # clean\n",
    "    df_clean = apply_cleaning(df_split)\n",
    "\n",
    "    # preview\n",
    "    print(df_clean.head(2))\n",
    "\n",
    "    # save\n",
    "    out_path = out_dir / f\"{split}.csv\"\n",
    "    df_clean.to_csv(out_path, index=False)\n",
    "    print(f\" -> saved cleaned split to {out_path} ({len(df_clean)} rows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3KylLHNl0bE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 3 - 0.5 points] Text Encoding\n",
    "To train a neural sexism classifier, you first need to encode text into numerical format.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr1lTHUVOXff",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* You are **free** to pick any embedding dimension.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6NNMEjWOZQr",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What about OOV tokens?\n",
    "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
    "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., ``<UNK>``) and a **static** embedding.\n",
    "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90UztlGUObXk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More about OOV\n",
    "\n",
    "For a given token:\n",
    "\n",
    "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
    "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n",
    "\n",
    "Your vocabulary **should**:\n",
    "\n",
    "* Contain all tokens in train set; or\n",
    "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GloVe] Loading glove-wiki-gigaword-100 (cached in ~/gensim-data)...\n",
      "\n",
      "=== Task 3 summary ===\n",
      "Vocabulary size (incl. PAD/UNK): 7842\n",
      "Embedding dimension: 100\n",
      "TRAIN tokens OOV in GloVe (random static vectors assigned): 718\n",
      "Number of TRAIN sequences containing <UNK>: 0  (expected: 0)\n",
      "MAX_LEN (95th percentile on TRAIN): 51\n",
      "Shapes -> X_train, X_val, X_test: (2212, 51) (115, 51) (217, 51)\n",
      "Embeddings matrix shape: (7842, 100)\n",
      "Saved to: C:\\CODING\\NLP-Project\\A1\\embeddings\n"
     ]
    }
   ],
   "source": [
    "# === TASK 3 — GloVe embeddings with explicit OOV handling ===\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.downloader as gloader  # we use gensim's pre-trained GloVe \n",
    "\n",
    "# ----------------- Configuration -----------------\n",
    "PROCESSED_DIR = Path(\"processed\")\n",
    "# We assume Task 2 already produced these cleaned CSVs with columns: id_EXIST, lang, tweet, label\n",
    "TRAIN_CSV = PROCESSED_DIR / \"train.csv\"\n",
    "VAL_CSV   = PROCESSED_DIR / \"validation.csv\"\n",
    "TEST_CSV  = PROCESSED_DIR / \"test.csv\"\n",
    "\n",
    "# Pick a GloVe model and make sure EMB_DIM matches it\n",
    "MODEL_NAME = \"glove-wiki-gigaword-100\"  # available: 50 | 100 | 200 | 300\n",
    "EMB_DIM = 100                           # must equal the dimension of MODEL_NAME\n",
    "\n",
    "# Fixed RNG for reproducibility (important for random OOV initialization)\n",
    "SEED = 13\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Reserve two special tokens:\n",
    "# - <PAD> (index 0) to pad sequences to a fixed length; embedding is all-zeros\n",
    "# - <UNK> (index 1) for tokens unseen in TRAIN but appearing in VAL/TEST; embedding is static\n",
    "SPECIAL_TOKENS = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "PAD_IDX = SPECIAL_TOKENS[\"<PAD>\"]\n",
    "UNK_IDX = SPECIAL_TOKENS[\"<UNK>\"]\n",
    "\n",
    "# ----------------- Load cleaned splits (Task 2 outputs) -----------------\n",
    "# We only cast the label to int; tweets stay as strings\n",
    "df_tr = pd.read_csv(TRAIN_CSV)\n",
    "df_va = pd.read_csv(VAL_CSV)\n",
    "df_te = pd.read_csv(TEST_CSV)\n",
    "\n",
    "y_tr = df_tr[\"label\"].astype(int).to_numpy()\n",
    "y_va = df_va[\"label\"].astype(int).to_numpy()\n",
    "y_te = df_te[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "# Simple tokenizer:\n",
    "# After Task 2 cleaning (URLs, mentions, punctuation removed and lemmatized),\n",
    "# whitespace split is sufficient and fast.\n",
    "def tokenize(s: str):\n",
    "    return s.strip().split()\n",
    "\n",
    "X_tr_tokens = [tokenize(t) for t in df_tr[\"tweet\"].astype(str)]\n",
    "X_va_tokens = [tokenize(t) for t in df_va[\"tweet\"].astype(str)]\n",
    "X_te_tokens = [tokenize(t) for t in df_te[\"tweet\"].astype(str)]\n",
    "\n",
    "# ----------------- Load GloVe vectors via gensim -----------------\n",
    "# gensim will download once to ~/gensim-data and then cache the model;\n",
    "# using this avoids shipping a large .txt with the project.\n",
    "print(f\"[GloVe] Loading {MODEL_NAME} (cached in ~/gensim-data)...\")\n",
    "kv = gloader.load(MODEL_NAME)  # KeyedVectors object with token -> vector lookups\n",
    "\n",
    "# We compute global mean/std of the pre-trained space to:\n",
    "# - initialize TRAIN OOV tokens with random vectors ~ N(mean, std)\n",
    "# - define <UNK> as the mean vector (static)\n",
    "glove_mean = kv.vectors.mean(axis=0).astype(np.float32)\n",
    "glove_std  = kv.vectors.std(axis=0).astype(np.float32)\n",
    "\n",
    "# ----------------- Build vocabulary from TRAIN only -----------------\n",
    "# Rationale:\n",
    "# - The assignment requires: include ALL TRAIN tokens in the vocabulary.\n",
    "# - If a TRAIN token exists in GloVe, use its pre-trained vector.\n",
    "# - If it does not, assign a static random vector drawn from N(glove_mean, glove_std).\n",
    "# - VAL/TEST tokens that are not in TRAIN's vocab are mapped to <UNK>.\n",
    "train_vocab = set()\n",
    "for toks in X_tr_tokens:\n",
    "    train_vocab.update(toks)\n",
    "\n",
    "# token_to_idx starts with special tokens; indices must align with the embedding matrix rows.\n",
    "token_to_idx = dict(SPECIAL_TOKENS)\n",
    "\n",
    "# Embedding matrix rows will be stacked in 'embeds' in the same order as indices.\n",
    "#  - Row 0 (<PAD>) is all zeros so it does not affect the model.\n",
    "#  - Row 1 (<UNK>) is a static \"generic\" embedding; we set it to the mean GloVe vector.\n",
    "embeds = [\n",
    "    np.zeros(EMB_DIM, dtype=np.float32),  # <PAD>\n",
    "    glove_mean.copy(),                     # <UNK>\n",
    "]\n",
    "\n",
    "oov_train = 0     # counter for TRAIN tokens missing in GloVe\n",
    "next_idx = len(SPECIAL_TOKENS)\n",
    "\n",
    "# Deterministic insertion order (sorted) to make experiments reproducible\n",
    "for tok in sorted(train_vocab):\n",
    "    token_to_idx[tok] = next_idx\n",
    "\n",
    "    if tok in kv.key_to_index:\n",
    "        # Known by GloVe: use the pre-trained vector\n",
    "        vec = kv.get_vector(tok)\n",
    "    else:\n",
    "        # OOV in TRAIN: initialize a STATIC vector matching GloVe's global distribution\n",
    "        # Motivation: keeps scale and variance consistent with the pre-trained space\n",
    "        vec = rng.normal(loc=glove_mean, scale=glove_std).astype(np.float32)\n",
    "        oov_train += 1\n",
    "\n",
    "    embeds.append(vec)\n",
    "    next_idx += 1\n",
    "\n",
    "# Final embedding matrix: shape = [vocab_size, EMB_DIM]\n",
    "embedding_matrix = np.vstack(embeds).astype(np.float32)\n",
    "\n",
    "# ----------------- Convert text to indices -----------------\n",
    "# TRAIN: every token should be in vocab (no <UNK> expected).\n",
    "# VAL/TEST: unseen tokens map to <UNK>.\n",
    "def tokens_to_ids(tokens, token2idx, unk_idx=UNK_IDX):\n",
    "    return [token2idx.get(t, unk_idx) for t in tokens]\n",
    "\n",
    "Xtr_ids = [tokens_to_ids(toks, token_to_idx) for toks in X_tr_tokens]\n",
    "Xva_ids = [tokens_to_ids(toks, token_to_idx) for toks in X_va_tokens]\n",
    "Xte_ids = [tokens_to_ids(toks, token_to_idx) for toks in X_te_tokens]\n",
    "\n",
    "# Sanity check: if TRAIN contains <UNK>, something went wrong (e.g., tokenization mismatch)\n",
    "unk_in_train = sum(UNK_IDX in seq for seq in Xtr_ids)\n",
    "\n",
    "# ----------------- Pad / truncate sequences to a fixed length -----------------\n",
    "# We choose MAX_LEN as the 95th percentile of TRAIN lengths:\n",
    "# - Motivation: keeps almost all content while preventing extreme outliers from bloating tensors.\n",
    "def infer_max_len(seqs, q=95):\n",
    "    lens = np.array([len(s) for s in seqs], dtype=np.int32)\n",
    "    return max(1, int(np.percentile(lens, q))) if len(lens) else 1\n",
    "\n",
    "MAX_LEN = infer_max_len(Xtr_ids, q=95)\n",
    "\n",
    "# Left-align and pad with <PAD> up to MAX_LEN; truncate longer sequences.\n",
    "def pad_truncate(seqs, max_len, pad_idx=PAD_IDX):\n",
    "    out = np.full((len(seqs), max_len), pad_idx, dtype=np.int32)\n",
    "    for i, s in enumerate(seqs):\n",
    "        out[i, :min(len(s), max_len)] = s[:max_len]\n",
    "    return out\n",
    "\n",
    "Xtr_mat = pad_truncate(Xtr_ids, MAX_LEN, PAD_IDX)\n",
    "Xva_mat = pad_truncate(Xva_ids, MAX_LEN, PAD_IDX)\n",
    "Xte_mat = pad_truncate(Xte_ids, MAX_LEN, PAD_IDX)\n",
    "\n",
    "# ----------------- Save artifacts for Task 4 -----------------\n",
    "# We persist exactly what the next tasks need:\n",
    "# - vocab.json: token -> index mapping (to tokenize new texts consistently)\n",
    "# - embeddings.npy: embedding matrix aligned with indices (row i = vector for index i)\n",
    "# - dataset_indices.npz: padded index matrices + labels + minimal metadata\n",
    "OUT_DIR = Path(\"embeddings\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(OUT_DIR / \"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(token_to_idx, f, ensure_ascii=False)\n",
    "\n",
    "np.save(OUT_DIR / \"embeddings.npy\", embedding_matrix)\n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_DIR / \"dataset_indices.npz\",\n",
    "    X_train=Xtr_mat, y_train=y_tr,\n",
    "    X_val=Xva_mat,  y_val=y_va,\n",
    "    X_test=Xte_mat, y_test=y_te,\n",
    "    pad_idx=PAD_IDX, unk_idx=UNK_IDX, max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "# ----------------- Textual summary (quick sanity-check) -----------------\n",
    "print(\"\\n=== Task 3 summary ===\")\n",
    "print(f\"Vocabulary size (incl. PAD/UNK): {embedding_matrix.shape[0]}\")\n",
    "print(f\"Embedding dimension: {embedding_matrix.shape[1]}\")\n",
    "print(f\"TRAIN tokens OOV in GloVe (random static vectors assigned): {oov_train}\")\n",
    "print(f\"Number of TRAIN sequences containing <UNK>: {unk_in_train}  (expected: 0)\")\n",
    "print(f\"MAX_LEN (95th percentile on TRAIN): {MAX_LEN}\")\n",
    "print(\"Shapes -> X_train, X_val, X_test:\", Xtr_mat.shape, Xva_mat.shape, Xte_mat.shape)\n",
    "print(\"Embeddings matrix shape:\", embedding_matrix.shape)\n",
    "print(f\"Saved to: {OUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (7842, 100) | X_train/X_val/X_test: (2212, 51) (115, 51) (217, 51)\n",
      "pad_idx: 0 unk_idx: 1 max_len: 51\n",
      "PAD vec (first 8): [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "UNK vec (first 8): [ 0.05209883 -0.09711445 -0.1380765   0.11075345 -0.02722748 -0.00326409\n",
      "  0.03176443 -0.05076874]\n",
      "\n",
      "[TRAIN] row=0 | label=3 | len(no-pad)=47/51\n",
      "indices: [7746, 197, 7302, 2480, 3530, 4661, 4170, 5568, 7680, 197, 1473, 5670, 4938, 4302, 3901, 623, 4402, 2238, 5621, 7609, 3437, 4249, 7185, 7051, 1574, 461, 2395, 7680, 3054, 4226] ...\n",
      "tokens : ['write', 'a', 'uni', 'essay', 'in', 'my', 'local', 'pub', 'with', 'a', 'coffee', 'random', 'old', 'man', 'keep', 'ask', 'me', 'drunk', 'question', 'when', 'i', 'm', 'try', 'to', 'concentrate', 'amp', 'end', 'with', 'good', 'luck'] ...\n",
      "id_EXIST=200002 | text: write a uni essay in my local pub with a coffee random old man keep ask me drunk question when i m try to concentrate amp end with good luck but you ll just end...\n",
      "embedding for token 'write' (idx=7746) -> first 8 dims:\n",
      " [-0.51063   0.48674  -0.073295 -0.14262   0.25711   0.84355  -0.67683\n",
      " -0.3107  ]\n",
      "\n",
      "[VAL] row=0 | label=0 | len(no-pad)=41/51\n",
      "indices: [7806, 6279, 6415, 4588, 4215, 3859, 5445, 7806, 5695, 197, 7078, 4966, 197, 2816, 1, 7555, 5695, 4957, 4152, 7001, 6944, 753, 3530, 4152, 4437, 6434, 3744, 6018, 404, 197] ...\n",
      "tokens : ['you', 'should', 'smile', 'more', 'love', 'just', 'pretend', 'you', 're', 'a', 'tory', 'open', 'a', 'food', '<UNK>', 'we', 're', 'only', 'live', 'through', 'the', 'bad', 'in', 'live', 'memory', 'so', 'it', 's', 'all', 'a'] ...\n",
      "id_EXIST=400001 | text: you should smile more love just pretend you re a tory open a food bank we re only live through the bad in live memory so it s all a bit of a giggle cheer up dar...\n",
      "embedding for token 'you' (idx=7806) -> first 8 dims:\n",
      " [-0.49886  0.76602  0.89751 -0.78547 -0.6855   0.62609 -0.39655  0.34913]\n",
      "\n",
      "[TEST] row=0 | label=0 | len(no-pad)=34/51\n",
      "indices: [64, 1878, 654, 6944, 5353, 4949, 197, 842, 6734, 3530, 4864, 7072, 753, 2727, 1861, 7051, 3033, 3530, 2245, 7051, 6944, 2891, 7547, 6898, 7555, 4019, 136, 4503, 481, 2741] ...\n",
      "tokens : ['1st', 'day', 'at', 'the', 'pool', 'on', 'a', 'beautiful', 'sunday', 'in', 'ny', 'too', 'bad', 'few', 'dare', 'to', 'go', 'in', 'due', 'to', 'the', 'frigid', 'water', 'temp', 'we', 'last', '45', 'min', 'and', 'figure'] ...\n",
      "id_EXIST=400178 | text: 1st day at the pool on a beautiful sunday in ny too bad few dare to go in due to the frigid water temp we last 45 min and figure we prove our point\n",
      "embedding for token '1st' (idx=64) -> first 8 dims:\n",
      " [-0.77972   0.08861   0.59284   0.18825  -0.097366 -0.23129   0.51996\n",
      " -0.015218]\n"
     ]
    }
   ],
   "source": [
    "# === Inspect artifacts from Task 3 (np.load) ===\n",
    "import numpy as np, json, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ART_DIR = Path(\"embeddings\")\n",
    "\n",
    "# load artifacts\n",
    "E = np.load(ART_DIR / \"embeddings.npy\")                       # (vocab_size, emb_dim)\n",
    "D = np.load(ART_DIR / \"dataset_indices.npz\", allow_pickle=False)\n",
    "tok2idx = json.load(open(ART_DIR / \"vocab.json\", \"r\", encoding=\"utf-8\"))\n",
    "idx2tok = {int(v): k for k, v in tok2idx.items()}\n",
    "\n",
    "# unpack arrays + meta\n",
    "Xtr, ytr = D[\"X_train\"], D[\"y_train\"]\n",
    "Xva, yva = D[\"X_val\"],   D[\"y_val\"]\n",
    "Xte, yte = D[\"X_test\"],  D[\"y_test\"]\n",
    "pad_idx, unk_idx, max_len = int(D[\"pad_idx\"]), int(D[\"unk_idx\"]), int(D[\"max_len\"])\n",
    "\n",
    "# (optional) original CSVs for id/text preview, if available\n",
    "df_tr = pd.read_csv(\"processed/train.csv\") if Path(\"processed/train.csv\").exists() else None\n",
    "df_va = pd.read_csv(\"processed/validation.csv\") if Path(\"processed/validation.csv\").exists() else None\n",
    "df_te = pd.read_csv(\"processed/test.csv\") if Path(\"processed/test.csv\").exists() else None\n",
    "dfs = {\"train\": df_tr, \"val\": df_va, \"test\": df_te}\n",
    "\n",
    "def decode(seq, drop_pad=True):\n",
    "    \"\"\"indices -> tokens (stop at first PAD for leggibilità).\"\"\"\n",
    "    toks = []\n",
    "    for i in seq:\n",
    "        i = int(i)\n",
    "        if drop_pad and i == pad_idx:\n",
    "            break\n",
    "        toks.append(idx2tok.get(i, \"<NA>\"))\n",
    "    return toks\n",
    "\n",
    "def show_example(split=\"train\", i=0, show_embed=True, preview_chars=160):\n",
    "    X, y = {\"train\": (Xtr, ytr), \"val\": (Xva, yva), \"test\": (Xte, yte)}[split]\n",
    "    seq = X[i]\n",
    "    no_pad_len = int((seq != pad_idx).sum())\n",
    "    print(f\"\\n[{split.upper()}] row={i} | label={int(y[i])} | len(no-pad)={no_pad_len}/{len(seq)}\")\n",
    "    print(\"indices:\", seq[:min(30, len(seq))].tolist(), \"...\")\n",
    "    toks = decode(seq)\n",
    "    print(\"tokens :\", toks[:30], \"...\")\n",
    "    if dfs[split] is not None:\n",
    "        row = dfs[split].iloc[i]\n",
    "        print(f\"id_EXIST={row['id_EXIST']} | text: {str(row['tweet'])[:preview_chars]}{'...' if len(str(row['tweet']))>preview_chars else ''}\")\n",
    "    if show_embed and no_pad_len > 0:\n",
    "        # pick first non-pad token index\n",
    "        j = int(next(x for x in seq if int(x) != pad_idx))\n",
    "        print(f\"embedding for token '{idx2tok.get(j)}' (idx={j}) -> first 8 dims:\\n\", E[j][:8])\n",
    "\n",
    "# summary\n",
    "print(\"Embeddings:\", E.shape, \"| X_train/X_val/X_test:\", Xtr.shape, Xva.shape, Xte.shape)\n",
    "print(\"pad_idx:\", pad_idx, \"unk_idx:\", unk_idx, \"max_len:\", max_len)\n",
    "print(\"PAD vec (first 8):\", E[pad_idx][:8])\n",
    "print(\"UNK vec (first 8):\", E[unk_idx][:8])\n",
    "\n",
    "# show a few examples\n",
    "show_example(\"train\", 0)\n",
    "show_example(\"val\", 0)\n",
    "show_example(\"test\", 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JLnuLGHGAUT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 4 - 1.0 points] Model definition\n",
    "\n",
    "You are now tasked to define your sexism classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQFI9J-JOfXD",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "\n",
    "* **Stacked**: add an additional Bidirectional LSTM layer to the Baseline model.\n",
    "\n",
    "**Note**: You are **free** to experiment with hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jALc_qYGS2E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Token to embedding mapping\n",
    "\n",
    "You can follow two approaches for encoding tokens in your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Work directly with embeddings\n",
    "\n",
    "- Compute the embedding of each input token\n",
    "- Feed the mini-batches of shape ``(batch_size, # tokens, embedding_dim)`` to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Work with Embedding layer\n",
    "\n",
    "- Encode input tokens to token ids\n",
    "- Define a Embedding layer as the first layer of your model\n",
    "- Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)\n",
    "- Initialize the Embedding layer with the computed embedding matrix\n",
    "- You are **free** to set the Embedding layer trainable or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions (BiLSTM)\n",
    "\n",
    "Artifacts from Task 3:\n",
    "- `embeddings/embeddings.npy` — embedding matrix (shape: `[vocab_size, embedding_dim]`)\n",
    "- `embeddings/dataset_indices.npz` — indexed & padded datasets and meta (`max_len`, `pad_idx`, `unk_idx`)\n",
    "\n",
    "We implement **two minimal architectures** for each approach:\n",
    "- **Baseline:** 1×Bidirectional LSTM → Dense(softmax)\n",
    "- **Stacked:**  2×Bidirectional LSTM → Dense(softmax)\n",
    "\n",
    "Approaches (as in the notebook order):\n",
    "- **Approach A — Work directly with embeddings** (inputs are `(batch, max_len, embedding_dim)`)\n",
    "- **Approach B — Work with Embedding layer** (inputs are token ids; first layer is `Embedding`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix: (7842, 100)\n",
      "X_train/X_val/X_test: (2212, 51) (115, 51) (217, 51)\n",
      "max_len: 51 | pad_idx: 0 | unk_idx: 1 | num_classes: 4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "EMB_DIR = Path(\"embeddings\")\n",
    "\n",
    "# Load embedding matrix and dataset meta (for shapes only)\n",
    "E = np.load(EMB_DIR / \"embeddings.npy\")                      # (vocab_size, embedding_dim)\n",
    "D = np.load(EMB_DIR / \"dataset_indices.npz\", allow_pickle=False)\n",
    "\n",
    "X_train, X_val, X_test = D[\"X_train\"], D[\"X_val\"], D[\"X_test\"]\n",
    "y_train, y_val, y_test = D[\"y_train\"], D[\"y_val\"], D[\"y_test\"]\n",
    "pad_idx, unk_idx, max_len = int(D[\"pad_idx\"]), int(D[\"unk_idx\"]), int(D[\"max_len\"])\n",
    "\n",
    "vocab_size    = int(E.shape[0])\n",
    "embedding_dim = int(E.shape[1])\n",
    "num_classes   = int(np.max(y_train)) + 1  # expected 4 for this task\n",
    "\n",
    "print(\"Embedding matrix:\", E.shape)\n",
    "print(\"X_train/X_val/X_test:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"max_len:\", max_len, \"| pad_idx:\", pad_idx, \"| unk_idx:\", unk_idx, \"| num_classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach A — Work directly with embeddings (inputs = precomputed embeddings)\n",
    "\n",
    "- Inputs have shape `(batch, max_len, embedding_dim)`; each time-step is already an embedding vector.\n",
    "- We **do not** use an Embedding layer in this approach.\n",
    "- Padding rows are the **all-zero** vector by construction (from Task 3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"baseline_bilstm_direct\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"baseline_bilstm_direct\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embeddings (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm (\u001b[38;5;33mBidirectional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,524</span> (920.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,524\u001b[0m (920.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,524</span> (920.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,524\u001b[0m (920.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"stacked_bilstm_direct\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"stacked_bilstm_direct\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embeddings (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bilstm_2 (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,364</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m399,364\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,364</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m399,364\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Hyperparameters\n",
    "BILSTM_UNITS_BASE = 128   # Baseline single BiLSTM\n",
    "BILSTM_UNITS_1    = 128   # Stacked: first layer\n",
    "BILSTM_UNITS_2    = 64    # Stacked: second layer\n",
    "\n",
    "# Baseline: (batch, max_len, emb_dim) -> 1×BiLSTM -> Dense\n",
    "def build_baseline_direct():\n",
    "    inputs = layers.Input(shape=(max_len, embedding_dim), dtype=\"float32\", name=\"embeddings\")\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_BASE, return_sequences=False), name=\"bilstm\")(inputs)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"classifier\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"baseline_bilstm_direct\")\n",
    "\n",
    "# Stacked (minimal): (batch, max_len, emb_dim) -> 2×BiLSTM -> Dense\n",
    "def build_stacked_direct():\n",
    "    inputs = layers.Input(shape=(max_len, embedding_dim), dtype=\"float32\", name=\"embeddings\")\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_1, return_sequences=True),  name=\"bilstm_1\")(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_2, return_sequences=False), name=\"bilstm_2\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"classifier\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"stacked_bilstm_direct\")\n",
    "\n",
    "baseline_direct = build_baseline_direct()\n",
    "stacked_direct  = build_stacked_direct()\n",
    "\n",
    "baseline_direct.summary()\n",
    "stacked_direct.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach B — Work with Embedding layer (inputs = token ids)\n",
    "\n",
    "- Inputs are integer **token ids** from `dataset_indices.npz`.\n",
    "- First layer is `Embedding`, initialized with Task 3 matrix:\n",
    "  `Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[E], mask_zero=True)`\n",
    "- `mask_zero=True` makes LSTMs ignore padding tokens (requires `pad_idx == 0`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"baseline_bilstm_embedding\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"baseline_bilstm_embedding\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">784,200</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ encoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m784,200\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m234,496\u001b[0m │ encoder_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m1,028\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,019,724</span> (3.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,019,724\u001b[0m (3.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,019,724</span> (3.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,019,724\u001b[0m (3.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"stacked_bilstm_embedding\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"stacked_bilstm_embedding\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">784,200</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ encoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ bilstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │ bilstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m784,200\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m234,496\u001b[0m │ encoder_embeddin… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bilstm_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m164,352\u001b[0m │ bilstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │        \u001b[38;5;34m516\u001b[0m │ bilstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,564</span> (4.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,183,564\u001b[0m (4.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,564</span> (4.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,183,564\u001b[0m (4.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Safety: masking expects PAD index 0\n",
    "assert pad_idx == 0, \"mask_zero=True requires PAD index 0.\"\n",
    "\n",
    "# Toggle in Task 5 if you want to freeze or fine-tune embeddings\n",
    "EMB_TRAINABLE = True\n",
    "\n",
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[E],            # initialize with Task 3 weights\n",
    "    mask_zero=True,         # automatically ignores PAD tokens\n",
    "    name=\"encoder_embedding\",\n",
    "    trainable=EMB_TRAINABLE\n",
    ")\n",
    "\n",
    "# Baseline: Embedding -> 1×BiLSTM -> Dense\n",
    "def build_baseline_embedding():\n",
    "    inputs = layers.Input(shape=(max_len,), dtype=\"int32\", name=\"token_ids\")\n",
    "    x = embedding_layer(inputs)  # (batch, max_len, embedding_dim) with mask\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_BASE, return_sequences=False), name=\"bilstm\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"classifier\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"baseline_bilstm_embedding\")\n",
    "\n",
    "# Stacked: Embedding -> 2×BiLSTM -> Dense\n",
    "def build_stacked_embedding():\n",
    "    inputs = layers.Input(shape=(max_len,), dtype=\"int32\", name=\"token_ids\")\n",
    "    x = embedding_layer(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_1, return_sequences=True),  name=\"bilstm_1\")(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(BILSTM_UNITS_2, return_sequences=False), name=\"bilstm_2\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"classifier\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"stacked_bilstm_embedding\")\n",
    "\n",
    "baseline_emb = build_baseline_embedding()\n",
    "stacked_emb  = build_stacked_embedding()\n",
    "\n",
    "baseline_emb.summary()\n",
    "stacked_emb.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFjBgdiRG3wD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 5 - 1.0 points] Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate the Baseline and Stacked models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWPK4umGOjtT",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Instructions\n",
    "\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute macro F1-score, precision, and recall metrics on the validation set.\n",
    "* Report average and standard deviation measures over seeds for each metric.\n",
    "* Pick the **best** performing model according to the observed validation set performance (use macro F1-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSy9sPwYHUoD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 6 - 1.0 points] Transformers\n",
    "\n",
    "In this section, you will use a transformer model specifically trained for hate speech detection, namely [Twitter-roBERTa-base for Hate Speech Detection](https://huggingface.co/cardiffnlp/twitter-roberta-base-hate).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Relevant Material\n",
    "- Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "- **Load the Tokenizer and Model**\n",
    "\n",
    "- **Preprocess the Dataset**:\n",
    "   You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.\n",
    "\n",
    "- **Train the Model**:\n",
    "   Use the `Trainer` to train the model on your training data.\n",
    "\n",
    "- **Evaluate the Model on the Test Set** using the same metrics used for LSTM-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gtiG2mAL3HM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 7 - 0.5 points] Error Analysis\n",
    "\n",
    "After evaluating the model, perform a brief error analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    " - Review the results and identify common errors.\n",
    "\n",
    " - Summarize your findings regarding the errors and their impact on performance (e.g. but not limited to Out-of-Vocabulary (OOV) words, data imbalance, and performance differences between the custom model and the transformer...)\n",
    " - Suggest possible solutions to address the identified errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P42XYjb6K3k5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 8 - 0.5 points] Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9oXSaW1K5S7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHw2L6PlLDyE",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recommendations\n",
    "\n",
    "The report is **not a copy-paste** of graphs, tables, and command outputs.\n",
    "\n",
    "* Summarize classification performance in Table format.\n",
    "* **Do not** report command outputs or screenshots.\n",
    "* Report learning curves in Figure format.\n",
    "* The error analysis section should summarize your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMUqh1utLflM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Submission\n",
    "\n",
    "* **Submit** your report in PDF format.\n",
    "* **Submit** your python notebook.\n",
    "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
    "* You can upload **model weights** in a cloud repository and report the link in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus Points\n",
    "Bonus points are arbitrarily assigned based on significant contributions such as:\n",
    "- Outstanding error analysis\n",
    "- Masterclass code organization\n",
    "- Suitable extensions\n",
    "\n",
    "**Note**: bonus points are only assigned if all task points are attributed (i.e., 6/6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Possible Suggestions for Bonus Points:**\n",
    "- **Try other preprocessing strategies**: e.g., but not limited to, explore techniques tailored specifically for tweets or  methods that are common in social media text.\n",
    "- **Experiment with other custom architectures or models from HuggingFace**\n",
    "- **Explore Spanish tweets**: e.g., but not limited to, leverage multilingual models to process Spanish tweets and assess their performance compared to monolingual models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypagJed7LheY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAQ\n",
    "\n",
    "Please check this frequently asked questions before contacting us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BjMk5e_M4n7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trainable Embeddings\n",
    "\n",
    "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8TVgpYlM6s5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model architecture\n",
    "\n",
    "You **should not** change the architecture of a model (i.e., its layers).\n",
    "\n",
    "However, you are **free** to play with their hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia6IapI1M_A7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neural Libraries\n",
    "\n",
    "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1WcrpemNEQm",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Robust Evaluation\n",
    "\n",
    "Each model is trained with at least 3 random seeds.\n",
    "\n",
    "Task 5 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expected Results\n",
    "\n",
    "Task 2 leaderboard reports around 40-50 F1-score.\n",
    "However, note that they perform a hierarchical classification.\n",
    "\n",
    "That said, results around 30-40 F1-score are **expected** given the task's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mVe5dqzNI_u",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Selection for Analysis\n",
    "\n",
    "To carry out the error analysis you are **free** to either\n",
    "\n",
    "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
    "* Perform ensembling via, for instance, majority voting to obtain a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8a4pDKSNKzI",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error Analysis\n",
    "\n",
    "Some topics for discussion include:\n",
    "   * Precision/Recall curves.\n",
    "   * Confusion matrices.\n",
    "   * Specific misclassified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xmMKE7vLu-y",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# The End\n",
    "\n",
    "Feel free to reach out for questions/doubts!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOrxI+uaofLerXT9gw1DmbE",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
